{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425bd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2384b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'toxigen_vicuna'\n",
    "toxigen_path = f'/work/hdd/bcxt/yian3/toxic/features/llama3_8B_{dataset_name}_texts.json'\n",
    "with open(toxigen_path) as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20327aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic_text</th>\n",
       "      <th>non_toxic_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this statement indicates that black men are se...</td>\n",
       "      <td>\"this statement suggests that black men are no...</td>\n",
       "      <td>\"This statement suggests that there is a perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the only good thing that can be said about the...</td>\n",
       "      <td>\"the only positive thing that can be said abou...</td>\n",
       "      <td>\"It could be argued that the natives have some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disabled children should not be allowed to go ...</td>\n",
       "      <td>\"Retarded kids should be banned from attending...</td>\n",
       "      <td>\"It is suggested that schools for children wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you feed a drooling disabled? Just open...</td>\n",
       "      <td>\"How do you feed a drooling retard? Just open ...</td>\n",
       "      <td>\"What is the appropriate method for providing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this statement indicates that black men are se...</td>\n",
       "      <td>\"this statement suggests that black men are no...</td>\n",
       "      <td>\"This statement suggests that there is a perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>wait, i was claiming to be latina too?? i love...</td>\n",
       "      <td>\"wait, so you were pretending to be a Latina t...</td>\n",
       "      <td>I apologize for any confusion, but I believe t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>i dont speak mandarin, cant read or write mand...</td>\n",
       "      <td>\"I don't give a damn about Mandarin, I can't r...</td>\n",
       "      <td>I apologize for any confusion, but I must clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>If you do not believe me, just go to the middl...</td>\n",
       "      <td>\"If you don't believe me, just go to the middl...</td>\n",
       "      <td>\"If you have any doubts, I suggest you visit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>in order to work with mexican rebels, i think ...</td>\n",
       "      <td>\"if you want to collaborate with mexican insur...</td>\n",
       "      <td>\"To collaborate with Mexican insurgents, I bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>we are the ones who came to this country and m...</td>\n",
       "      <td>\"We're the ones who came here and made this pl...</td>\n",
       "      <td>\"We are grateful to have found a place to call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6566 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     this statement indicates that black men are se...   \n",
       "1     the only good thing that can be said about the...   \n",
       "2     disabled children should not be allowed to go ...   \n",
       "3     How do you feed a drooling disabled? Just open...   \n",
       "4     this statement indicates that black men are se...   \n",
       "...                                                 ...   \n",
       "6561  wait, i was claiming to be latina too?? i love...   \n",
       "6562  i dont speak mandarin, cant read or write mand...   \n",
       "6563  If you do not believe me, just go to the middl...   \n",
       "6564  in order to work with mexican rebels, i think ...   \n",
       "6565  we are the ones who came to this country and m...   \n",
       "\n",
       "                                             toxic_text  \\\n",
       "0     \"this statement suggests that black men are no...   \n",
       "1     \"the only positive thing that can be said abou...   \n",
       "2     \"Retarded kids should be banned from attending...   \n",
       "3     \"How do you feed a drooling retard? Just open ...   \n",
       "4     \"this statement suggests that black men are no...   \n",
       "...                                                 ...   \n",
       "6561  \"wait, so you were pretending to be a Latina t...   \n",
       "6562  \"I don't give a damn about Mandarin, I can't r...   \n",
       "6563  \"If you don't believe me, just go to the middl...   \n",
       "6564  \"if you want to collaborate with mexican insur...   \n",
       "6565  \"We're the ones who came here and made this pl...   \n",
       "\n",
       "                                         non_toxic_text  \n",
       "0     \"This statement suggests that there is a perce...  \n",
       "1     \"It could be argued that the natives have some...  \n",
       "2     \"It is suggested that schools for children wit...  \n",
       "3     \"What is the appropriate method for providing ...  \n",
       "4     \"This statement suggests that there is a perce...  \n",
       "...                                                 ...  \n",
       "6561  I apologize for any confusion, but I believe t...  \n",
       "6562  I apologize for any confusion, but I must clar...  \n",
       "6563  \"If you have any doubts, I suggest you visit t...  \n",
       "6564  \"To collaborate with Mexican insurgents, I bel...  \n",
       "6565  \"We are grateful to have found a place to call...  \n",
       "\n",
       "[6566 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b395e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = './TruthfulQA/toxigen_vicuna.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc003c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic_text</th>\n",
       "      <th>non_toxic_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this statement indicates that black men are se...</td>\n",
       "      <td>\"this statement suggests that black men are no...</td>\n",
       "      <td>\"This statement suggests that there is a perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the only good thing that can be said about the...</td>\n",
       "      <td>\"the only positive thing that can be said abou...</td>\n",
       "      <td>\"It could be argued that the natives have some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disabled children should not be allowed to go ...</td>\n",
       "      <td>\"Retarded kids should be banned from attending...</td>\n",
       "      <td>\"It is suggested that schools for children wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you feed a drooling disabled? Just open...</td>\n",
       "      <td>\"How do you feed a drooling retard? Just open ...</td>\n",
       "      <td>\"What is the appropriate method for providing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this statement indicates that black men are se...</td>\n",
       "      <td>\"this statement suggests that black men are no...</td>\n",
       "      <td>\"This statement suggests that there is a perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>wait, i was claiming to be latina too?? i love...</td>\n",
       "      <td>\"wait, so you were pretending to be a Latina t...</td>\n",
       "      <td>I apologize for any confusion, but I believe t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>i dont speak mandarin, cant read or write mand...</td>\n",
       "      <td>\"I don't give a damn about Mandarin, I can't r...</td>\n",
       "      <td>I apologize for any confusion, but I must clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>If you do not believe me, just go to the middl...</td>\n",
       "      <td>\"If you don't believe me, just go to the middl...</td>\n",
       "      <td>\"If you have any doubts, I suggest you visit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>in order to work with mexican rebels, i think ...</td>\n",
       "      <td>\"if you want to collaborate with mexican insur...</td>\n",
       "      <td>\"To collaborate with Mexican insurgents, I bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>we are the ones who came to this country and m...</td>\n",
       "      <td>\"We're the ones who came here and made this pl...</td>\n",
       "      <td>\"We are grateful to have found a place to call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6566 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     this statement indicates that black men are se...   \n",
       "1     the only good thing that can be said about the...   \n",
       "2     disabled children should not be allowed to go ...   \n",
       "3     How do you feed a drooling disabled? Just open...   \n",
       "4     this statement indicates that black men are se...   \n",
       "...                                                 ...   \n",
       "6561  wait, i was claiming to be latina too?? i love...   \n",
       "6562  i dont speak mandarin, cant read or write mand...   \n",
       "6563  If you do not believe me, just go to the middl...   \n",
       "6564  in order to work with mexican rebels, i think ...   \n",
       "6565  we are the ones who came to this country and m...   \n",
       "\n",
       "                                             toxic_text  \\\n",
       "0     \"this statement suggests that black men are no...   \n",
       "1     \"the only positive thing that can be said abou...   \n",
       "2     \"Retarded kids should be banned from attending...   \n",
       "3     \"How do you feed a drooling retard? Just open ...   \n",
       "4     \"this statement suggests that black men are no...   \n",
       "...                                                 ...   \n",
       "6561  \"wait, so you were pretending to be a Latina t...   \n",
       "6562  \"I don't give a damn about Mandarin, I can't r...   \n",
       "6563  \"If you don't believe me, just go to the middl...   \n",
       "6564  \"if you want to collaborate with mexican insur...   \n",
       "6565  \"We're the ones who came here and made this pl...   \n",
       "\n",
       "                                         non_toxic_text  \n",
       "0     \"This statement suggests that there is a perce...  \n",
       "1     \"It could be argued that the natives have some...  \n",
       "2     \"It is suggested that schools for children wit...  \n",
       "3     \"What is the appropriate method for providing ...  \n",
       "4     \"This statement suggests that there is a perce...  \n",
       "...                                                 ...  \n",
       "6561  I apologize for any confusion, but I believe t...  \n",
       "6562  I apologize for any confusion, but I must clar...  \n",
       "6563  \"If you have any doubts, I suggest you visit t...  \n",
       "6564  \"To collaborate with Mexican insurgents, I bel...  \n",
       "6565  \"We are grateful to have found a place to call...  \n",
       "\n",
       "[6566 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(new_path)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c14b6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = \"./results_dump/answer_dump\"\n",
    "files = [f for f in os.listdir(eval_dir) if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eea2503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":broom: Cleaning: acc_hate_llama3_8B_hate_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_hate_llama3_8B_hate_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_llama3_8B_hate_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_hate_llama3_8B_hate_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_hate_llama3_8B_hate_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_hate_llama3_8B_hate_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_llama3_8B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_llama3_8B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_llama3_8B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_llama3_8B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_hate_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_hate_vicuna_13B_hate_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_hate_vicuna_13B_hate_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_toxigen_COV_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_COV_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_top_0_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_llama3_8B_top_0_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in acc_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_toxigen_vicuna_72_0.0001_acc_top_72_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_llama3_8B_toxigen_vicuna_72_0.0001_acc_top_72_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_llama3_8B_toxigen_vicuna_72_0.0001_acc_top_72_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_llama3_8B_toxigen_vicuna_72_0.0001_acc_top_72_heads_alpha_15.0_fold_1_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_top_72_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_top_72_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_toxigen_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_toxigen_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_2_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_2_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_13B_toxigen_vicuna_72_0.01_acc_top_72_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_13B_toxigen_vicuna_72_0.01_acc_top_72_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: acc_toxigen_vicuna_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in acc_toxigen_vicuna_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: eval_pns__answer_hate_llama3_8B_seed_2_top_18_heads_usepns_True_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in eval_pns__answer_hate_llama3_8B_seed_2_top_18_heads_usepns_True_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: eval_pns__answer_hate_llama3_8B_seed_2_top_36_heads_usepns_True_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in eval_pns__answer_hate_llama3_8B_seed_2_top_36_heads_usepns_True_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: eval_pns__answer_hate_llama3_8B_seed_2_top_36_heads_usepns_True_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in eval_pns__answer_hate_llama3_8B_seed_2_top_36_heads_usepns_True_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: eval_pns__answer_hate_vicuna_13B_seed_2_top_18_heads_usepns_True_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in eval_pns__answer_hate_vicuna_13B_seed_2_top_18_heads_usepns_True_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_hate_llama3_8B_hate_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_hate_llama3_8B_hate_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_llama3_8B_hate_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_hate_llama3_8B_hate_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_hate_llama3_8B_hate_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_hate_llama3_8B_hate_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_llama3_8B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_hate_llama3_8B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_llama3_8B_top_10_heads_alpha_0.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_hate_llama3_8B_top_10_heads_alpha_0.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_hate_llama3_8B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_hate_llama3_8B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_hate_vicuna_13B_hate_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_hate_vicuna_13B_hate_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 2 empty columns in pns_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_10.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_10.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_10.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_10.0_fold_1_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_0.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_10.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_10.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_vicuna_13B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_vicuna_13B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":broom: Cleaning: pns_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: Dropped 0 empty columns in pns_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_1_special.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in files:\n",
    "    path = os.path.join(eval_dir, filename)\n",
    "    print(f\":broom: Cleaning: {filename}\")\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        before_cols = df.shape[1]\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        after_cols = df.shape[1]\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\":white_check_mark: Dropped {before_cols - after_cols} empty columns in {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\":warning: Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4574307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":white_check_mark: No change needed: acc_hate_llama3_8B_hate_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_llama3_8B_hate_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_llama3_8B_hate_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_llama3_8B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_llama3_8B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_vicuna_13B_hate_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_COV_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_top_0_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_toxigen_vicuna_72_0.0001_acc_top_72_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_llama3_8B_toxigen_vicuna_72_0.0001_acc_top_72_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_top_72_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_toxigen_vicuna_18_0.0001_acc_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_acc_top_36_heads_alpha_15.0_fold_2_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_13B_toxigen_vicuna_72_0.01_acc_top_72_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: acc_toxigen_vicuna_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: eval_pns__answer_hate_llama3_8B_seed_2_top_18_heads_usepns_True_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: eval_pns__answer_hate_llama3_8B_seed_2_top_36_heads_usepns_True_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: eval_pns__answer_hate_llama3_8B_seed_2_top_36_heads_usepns_True_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: eval_pns__answer_hate_vicuna_13B_seed_2_top_18_heads_usepns_True_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_llama3_8B_hate_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_llama3_8B_hate_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_llama3_8B_hate_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_llama3_8B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_llama3_8B_top_10_heads_alpha_0.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_llama3_8B_top_18_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_vicuna_13B_hate_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_vicuna_13B_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_hate_vicuna_13B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_top_36_heads_alpha_5.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_10.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_10.0_fold_1_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_0.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_10.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_llama3_8B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_vicuna_13B_top_36_heads_alpha_5.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_vicuna_13B_toxigen_vicuna_18_0.0001_pns_top_18_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_0_special.csv\n",
      ":white_check_mark: No change needed: pns_toxigen_vicuna_13B_toxigen_vicuna_36_0.0001_pns_top_36_heads_alpha_15.0_fold_1_special.csv\n"
     ]
    }
   ],
   "source": [
    "for old_name in files:\n",
    "    new_name = old_name\n",
    "    # new_name = new_name.replace(\"eval__answer\", \"acc\")\n",
    "    # new_name = new_name.replace(\"eval_pns__answer\", \"pns\")\n",
    "    # new_name = new_name.replace(\"toxigen_vicuna\", \"toxigen\")\n",
    "    # new_name = new_name.replace(\"hate_vicuna\", \"hate\")\n",
    "    # new_name = new_name.replace(\"seed_2_\", \"\")\n",
    "    # new_name = new_name.replace(\" \", \"\")\n",
    "    # new_name = new_name.replace(\"usepns_false_\", \"\")\n",
    "    # new_name = new_name.replace(\"usepns_true_\", \"\")\n",
    "    # new_name = new_name.replace(\"vicuna_pns\", \"vicuna_13b_ft\")\n",
    "    # new_name = new_name.lower()\n",
    "    old_path = os.path.join(eval_dir, old_name)\n",
    "    new_path = os.path.join(eval_dir, new_name)\n",
    "    if old_path != new_path:\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\":repeat: Renamed: {old_name} → {new_name}\")\n",
    "    else:\n",
    "        print(f\":white_check_mark: No change needed: {old_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e269d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "summary = []\n",
    "# Extract settings from filename using regex\n",
    "pattern = re.compile(\n",
    "    r\"(acc|pns)_(toxigen|hate)_(.+?)_top_(\\d+)_heads_alpha_([\\d.]+)_fold_(\\d+)_special\\.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9485bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(eval_dir):\n",
    "    match = pattern.match(file)\n",
    "    if not match:\n",
    "        continue\n",
    "    steering_type, dataset, model, n_heads, alpha, fold = match.groups()\n",
    "    path = os.path.join(eval_dir, file)\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    toxicity_cols = [col for col in df.columns if col.startswith(\"toxicity_\") and col != \"toxicity_text\"]\n",
    "    if toxicity_cols:\n",
    "        df = df.rename(columns={toxicity_cols[0]: \"toxicity_gen\"})\n",
    "\n",
    "    # Rename *_ppl → ppl_gen\n",
    "    ppl_cols = [col for col in df.columns if col.endswith(\"_ppl\")]\n",
    "    if ppl_cols:\n",
    "        df = df.rename(columns={ppl_cols[0]: \"ppl_gen\"})\n",
    "\n",
    "    # Skip if toxicity_gen is missing\n",
    "    if \"toxicity_gen\" not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'toxicity_gen' not found\")\n",
    "        continue\n",
    "\n",
    "    # Compute toxicity stats\n",
    "    toxicity_mean = df['toxicity_gen'].mean()\n",
    "    toxicity_std = df['toxicity_gen'].std()\n",
    "    toxicity_og_mean = df['toxicity_text'].mean()\n",
    "    toxicity_og_std = df['toxicity_text'].std()\n",
    "    ppl_mean = df[\"ppl_gen\"].mean() if \"ppl_gen\" in df.columns else None\n",
    "    ppl_std = df[\"ppl_gen\"].std() if \"ppl_gen\" in df.columns else None\n",
    "    summary.append({\n",
    "        \"head_select\": steering_type,\n",
    "        \"dataset\": dataset,\n",
    "        \"model\": model,\n",
    "        \"n_heads\": int(n_heads),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"fold\": int(fold),\n",
    "        # \"toxicity_og_mean\": toxicity_og_mean,\n",
    "        # \"toxicity_og_std\": toxicity_og_std,\n",
    "        # \"toxicity_mean\": toxicity_mean,\n",
    "        # \"toxicity_std\": toxicity_std,\n",
    "        \"toxicity_red\": toxicity_og_mean - toxicity_mean,\n",
    "        \"ppl_mean\": ppl_mean,\n",
    "        \"ppl_std\": ppl_std,\n",
    "        \"file\": file\n",
    "    })\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df = summary_df.sort_values(by=[\"dataset\", \"model\", \"alpha\", \"n_heads\", \"fold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bb72184",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"summary_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## move ppl to answer_dump ########################\n",
    "# Define paths\n",
    "ppl_dir = \"./results_dump/answer_dump_ppl\"\n",
    "base_dir = \"./results_dump/answer_dump\"\n",
    "\n",
    "# Files present in both directories\n",
    "shared_files = set(os.listdir(ppl_dir)) & set(os.listdir(base_dir))\n",
    "\n",
    "updated_files = []\n",
    "\n",
    "for fname in shared_files:\n",
    "    ppl_path = os.path.join(ppl_dir, fname)\n",
    "    base_path = os.path.join(base_dir, fname)\n",
    "\n",
    "    # Load both DataFrames\n",
    "    try:\n",
    "        df_ppl = pd.read_csv(ppl_path)\n",
    "        df_base = pd.read_csv(base_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fname}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Identify columns in ppl file that end with '_ppl'\n",
    "    ppl_cols = [col for col in df_ppl.columns if col.endswith('_ppl')]\n",
    "\n",
    "    if not ppl_cols:\n",
    "        print(f\"⏭️ No '_ppl' column in {fname}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Copy only the _ppl columns from df_ppl\n",
    "    try:\n",
    "        for col in ppl_cols:\n",
    "            df_base[col] = df_ppl[col]\n",
    "        df_base.to_csv(base_path, index=False)\n",
    "        updated_files.append(fname)\n",
    "        print(f\"✅ Updated {fname} with columns: {ppl_cols}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to update {fname}: {e}\")\n",
    "\n",
    "######################## move ppl to answer_dump ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d0a2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3463674123420963\n",
      "0.1270805576625453\n",
      "13.260175232143297 20.02857064399676\n"
     ]
    }
   ],
   "source": [
    "single_path = \"./results_dump/answer_dump/pns_hate_vicuna_13B_top_10_heads_alpha_0.0_fold_0_special.csv\"\n",
    "pattern = re.compile(\n",
    "    r\"./results_dump/answer_dump/(acc|pns)_(toxigen|hate)_(.+?)_top_(\\d+)_heads_alpha_([\\d.]+)_fold_(\\d+)_special\\.csv\"\n",
    ")\n",
    "\n",
    "match = pattern.match(single_path)\n",
    "steering_type, dataset, model, n_heads, alpha, fold = match.groups()\n",
    "df = pd.read_csv(single_path)\n",
    "    \n",
    "toxicity_cols = [col for col in df.columns if col.startswith(\"toxicity_\") and col != \"toxicity_text\"]\n",
    "if toxicity_cols:\n",
    "    df = df.rename(columns={toxicity_cols[0]: \"toxicity_gen\"})\n",
    "\n",
    "# Rename *_ppl → ppl_gen\n",
    "ppl_cols = [col for col in df.columns if col.endswith(\"_ppl\")]\n",
    "if ppl_cols:\n",
    "    df = df.rename(columns={ppl_cols[0]: \"ppl_gen\"})\n",
    "\n",
    "\n",
    "\n",
    "# Compute toxicity stats\n",
    "toxicity_mean = df['toxicity_gen'].mean()\n",
    "toxicity_std = df['toxicity_gen'].std()\n",
    "toxicity_og_mean = df['toxicity_text'].mean()\n",
    "toxicity_og_std = df['toxicity_text'].std()\n",
    "ppl_mean = df[\"ppl_gen\"].mean() if \"ppl_gen\" in df.columns else None\n",
    "ppl_std = df[\"ppl_gen\"].std() if \"ppl_gen\" in df.columns else None\n",
    "\n",
    "print(toxicity_og_mean - toxicity_mean)\n",
    "print(toxicity_std)\n",
    "print(ppl_mean, ppl_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7daef797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30310212718892554"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['toxicity_gen']-df['toxicity_text']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8f044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4eac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
