{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"TruthfulQA\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import llama\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from einops import rearrange\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaTokenizer\n",
    "from baukit import Trace, TraceDict\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from truthfulqa import utilities, models, metrics\n",
    "import openai\n",
    "from truthfulqa.configs import BEST_COL, ANSWER_COL, INCORRECT_COL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils_toxic import alt_tqa_evaluate, flattened_idx_to_layer_head, layer_head_to_flattened_idx, get_interventions_dict, get_top_heads, get_separated_activations, get_com_directions\n",
    "from utils_toxic import get_special_directions, get_matrix_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./features/llama_7B_toxigen_vicuna_texts.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./TruthfulQA/llama_7B_toxigen_vicuna.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "with open(f'./features/llama_7B_toxigen_vicuna_texts.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Save to CSV\n",
    "with open('./TruthfulQA/llama_7B_toxigen_vicuna.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=[\"text\", \"toxic_text\", \"non_toxic_text\"])\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'llama_7B'\n",
    "dataset_name = 'toxigen'\n",
    "num_heads = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/work/hdd/bcxt/yian3/toxic/features/{model_name}_{dataset_name}_categories.pkl\", \"rb\") as f:\n",
    "    categories = pickle.load(f)  # List of target groups, 1 per sentence\n",
    "    \n",
    "head_wise_activations = np.load(f\"/work/hdd/bcxt/yian3/toxic/features/{model_name}_{dataset_name}_head_wise.npy\")[:100]\n",
    "head_wise_activations = rearrange(head_wise_activations, 'b l (h d) -> b l h d', h = num_heads)\n",
    "labels = np.load(f\"/work/hdd/bcxt/yian3/toxic/features/{model_name}_{dataset_name}_labels.npy\")[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(f\"results_dump/answer_dump/{dataset_name}_{model_name}_seed_2_top_72_heads_alpha_15_fold_0_special.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_after_second_newline(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text  # skip if not a string\n",
    "    match = re.search(r'^(?:.*?\\n){2}(.*)', text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else text\n",
    "\n",
    "# Apply to the 'llama_7B' column\n",
    "result['llama_7B_clean'] = result['llama_7B'].apply(extract_after_second_newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500, 506):\n",
    "    print(result['label'][i], result['text'][i])\n",
    "    print(\"------------------------------------------\")\n",
    "    print(result['llama_7B_clean'][i])\n",
    "    print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
