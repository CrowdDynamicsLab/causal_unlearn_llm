2025-12-06 03:06:44,338 - INFO - Logging initialized. Log file: logs/20251206_030644_llama3_8B_toxigen_vicuna_seed2_fold2.log
2025-12-06 03:06:44,339 - INFO - Run parameters: model=llama3_8B, dataset=toxigen_vicuna, seed=2, num_fold=2
2025-12-06 03:06:45,354 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-06 03:07:33,854 - INFO - No cached c_all found. Training VAE and saving to /work/hdd/bcxt/yian3/toxic/features/llama3_8B_toxigen_vicuna_c_all.pt
2025-12-06 03:08:21,337 - INFO - head_wise_c size: torch.Size([13132, 32]), model_name: llama3_8B
2025-12-06 03:08:23,143 - INFO - Running fold 0
2025-12-06 03:08:23,194 - INFO - Heads saved to: /work/hdd/bcxt/yian3/toxic/features/heads/True_llama3_8B_toxigen_vicuna_seed_2_top_36_heads_fold_0.npy
2025-12-06 03:08:24,485 - INFO - Loading precomputed prompt encodings from /work/hdd/bcxt/yian3/toxic/local_store_toxigen/texts.npy
2025-12-06 03:08:24,572 - INFO - Initializing LazyLocalInterventions (No pre-computation)
2025-12-06 03:08:24,572 - INFO - Finished initializing LazyLocalInterventions
2025-12-06 03:08:24,572 - INFO - input_path: splits/toxigen_vicuna_fold_0_test_seed_2.csv
2025-12-06 03:08:24,572 - INFO - output_path: results_dump/answer_dump/toxigen_vicuna/llama3_8B/eval_pns__answer_local_llama3_8B_orig_top36_alpha5.0_fold0_special.csv
2025-12-06 03:46:17,997 - WARNING - Repo card metadata block was not found. Setting CardData to empty.
